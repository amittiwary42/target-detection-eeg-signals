{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-rb6A6hPI2C"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.metrics import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "import tensorflow as tf\n",
    "import keras.utils as utils\n",
    "import scipy.io as scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YYR7sVxYPI2J"
   },
   "outputs": [],
   "source": [
    "train_0_files = os.listdir('./train/0')\n",
    "train_1_files = os.listdir('./train/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1698,
     "status": "ok",
     "timestamp": 1549568213262,
     "user": {
      "displayName": "AMIT TIWARY",
      "photoUrl": "https://lh4.googleusercontent.com/-89DLdjchEVs/AAAAAAAAAAI/AAAAAAAAAAo/jtB5nq61tAg/s64/photo.jpg",
      "userId": "15098214295944816708"
     },
     "user_tz": -330
    },
    "id": "aW2ZLE2fbD3Q",
    "outputId": "55e6abe1-eb29-40ef-a51a-cf59732d1d73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12750"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_0_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5P0DYZGZPI2N"
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Hi7pA0n1PI2P"
   },
   "outputs": [],
   "source": [
    "for file in train_0_files:\n",
    "    path = os.path.join('./train/0',file)\n",
    "    mat = scipy.loadmat(path)\n",
    "    X_train.append(mat['eegdata'])\n",
    "    y_train.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7zuYqjoQPI2T"
   },
   "outputs": [],
   "source": [
    "for file in train_1_files:\n",
    "    path = os.path.join('./train/1',file)\n",
    "    mat = scipy.loadmat(path)\n",
    "    X_train.append(mat['eegdata'])\n",
    "    y_train.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Cssqf0nfPI2U"
   },
   "outputs": [],
   "source": [
    "X = np.array(X_train)\n",
    "y = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1122,
     "status": "ok",
     "timestamp": 1549568226443,
     "user": {
      "displayName": "AMIT TIWARY",
      "photoUrl": "https://lh4.googleusercontent.com/-89DLdjchEVs/AAAAAAAAAAI/AAAAAAAAAAo/jtB5nq61tAg/s64/photo.jpg",
      "userId": "15098214295944816708"
     },
     "user_tz": -330
    },
    "id": "C7PX44dYPI2X",
    "outputId": "16468175-ed3b-400e-a2b6-1fe716a617d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 64, 160)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18360, 64, 160)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14688, 64, 160)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DRf0AeRkPI2g"
   },
   "outputs": [],
   "source": [
    "class DataLoader(utils.Sequence):\n",
    "    def __init__(self, X, Y, batch_size = 64):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        perm_inds = np.arange(len(self.X))\n",
    "        np.random.shuffle(perm_inds)\n",
    "        self.X = self.X[perm_inds]\n",
    "        self.Y = self.Y[perm_inds]\n",
    "    \n",
    "    def process(self,y,arr):\n",
    "        #print(y.shape)\n",
    "        for i in range(64):\n",
    "            y[i][0][4]=arr[i][21]\n",
    "            y[i][0][5]=arr[i][22]\n",
    "            y[i][0][6]=arr[i][23]\n",
    "            y[i][1][3]=arr[i][24]\n",
    "            y[i][1][4]=arr[i][25]\n",
    "            y[i][1][5]=arr[i][26]\n",
    "            y[i][1][6]=arr[i][27]\n",
    "            y[i][1][7]=arr[i][28]\n",
    "            y[i][2][1]=arr[i][29]\n",
    "            y[i][2][2]=arr[i][30]\n",
    "            y[i][2][3]=arr[i][31]\n",
    "            y[i][2][4]=arr[i][32]\n",
    "            y[i][2][5]=arr[i][33]\n",
    "            y[i][2][6]=arr[i][34]\n",
    "            y[i][2][7]=arr[i][35]\n",
    "            y[i][2][8]=arr[i][36]\n",
    "            y[i][2][9]=arr[i][37]\n",
    "            y[i][3][1]=arr[i][38]\n",
    "            y[i][3][2]=arr[i][0]\n",
    "            y[i][3][3]=arr[i][1]\n",
    "            y[i][3][4]=arr[i][2]\n",
    "            y[i][3][5]=arr[i][3]\n",
    "            y[i][3][6]=arr[i][4]\n",
    "            y[i][3][7]=arr[i][5]\n",
    "            y[i][3][8]=arr[i][6]\n",
    "            y[i][3][9]=arr[i][39]\n",
    "            y[i][4][0]=arr[i][42]\n",
    "            y[i][4][1]=arr[i][40]\n",
    "            y[i][4][2]=arr[i][7]\n",
    "            y[i][4][3]=arr[i][8]\n",
    "            y[i][4][4]=arr[i][9]\n",
    "            y[i][4][5]=arr[i][10]\n",
    "            y[i][4][6]=arr[i][11]\n",
    "            y[i][4][7]=arr[i][12]\n",
    "            y[i][4][8]=arr[i][13]\n",
    "            y[i][4][9]=arr[i][41]\n",
    "            y[i][4][10]=arr[i][43]\n",
    "            y[i][5][1]=arr[i][44]\n",
    "            y[i][5][2]=arr[i][14]\n",
    "            y[i][5][3]=arr[i][15]\n",
    "            y[i][5][4]=arr[i][16]\n",
    "            y[i][5][5]=arr[i][17]\n",
    "            y[i][5][6]=arr[i][18]\n",
    "            y[i][5][7]=arr[i][19]\n",
    "            y[i][5][8]=arr[i][20]\n",
    "            y[i][5][9]=arr[i][45]\n",
    "            y[i][6][1]=arr[i][46]\n",
    "            y[i][6][2]=arr[i][47]\n",
    "            y[i][6][3]=arr[i][48]\n",
    "            y[i][6][4]=arr[i][49]\n",
    "            y[i][6][5]=arr[i][50]\n",
    "            y[i][6][6]=arr[i][51]\n",
    "            y[i][6][7]=arr[i][52]\n",
    "            y[i][6][8]=arr[i][53]\n",
    "            y[i][6][9]=arr[i][54]\n",
    "            y[i][7][3]=arr[i][55]\n",
    "            y[i][7][4]=arr[i][56]\n",
    "            y[i][7][5]=arr[i][57]\n",
    "            y[i][7][6]=arr[i][58]\n",
    "            y[i][7][7]=arr[i][59]\n",
    "            y[i][8][4]=arr[i][60]\n",
    "            y[i][8][5]=arr[i][61]\n",
    "            y[i][8][6]=arr[i][62]\n",
    "            y[i][9][5]=arr[i][63]\n",
    "        return y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)//self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X_batch = self.X[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        Y_batch = self.Y[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        y = np.zeros((64,10,11,160))\n",
    "        #print(X_batch.shape)\n",
    "        X_batch = self.process(y,X_batch)\n",
    "        X_batch=X_batch.reshape(-1,160,10,11,1)\n",
    "        #print(X_batch.shape)\n",
    "        #X_batch=np.moveaxis(y,3,1)\n",
    "        return X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "E0ZFq0mzd_9E"
   },
   "outputs": [],
   "source": [
    "s = np.zeros((64,160,10,11))\n",
    "s=s[:,:,:,:,None]\n",
    "#s=np.moveaxis(s,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1305,
     "status": "ok",
     "timestamp": 1549569337800,
     "user": {
      "displayName": "AMIT TIWARY",
      "photoUrl": "https://lh4.googleusercontent.com/-89DLdjchEVs/AAAAAAAAAAI/AAAAAAAAAAo/jtB5nq61tAg/s64/photo.jpg",
      "userId": "15098214295944816708"
     },
     "user_tz": -330
    },
    "id": "cpqTkXftgon7",
    "outputId": "d5542126-1d07-4169-e89e-123a8e2c9697"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 160, 10, 11, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2577,
     "status": "ok",
     "timestamp": 1549569422221,
     "user": {
      "displayName": "AMIT TIWARY",
      "photoUrl": "https://lh4.googleusercontent.com/-89DLdjchEVs/AAAAAAAAAAI/AAAAAAAAAAo/jtB5nq61tAg/s64/photo.jpg",
      "userId": "15098214295944816708"
     },
     "user_tz": -330
    },
    "id": "VeOKsyC2PI2r",
    "outputId": "4fbd8afc-9f4e-4188-8e92-4e74d1777611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 160, 10, 11, 1)    4         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 160, 8, 9, 3)      444       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 160, 8, 9, 3)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 160, 8, 9, 3)      12        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, 160, 6, 7, 3)      660       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 160, 6, 7, 3)      12        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 20160)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20160)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 20161     \n",
      "=================================================================\n",
      "Total params: 21,293\n",
      "Trainable params: 21,279\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#ConvLSTM Model\n",
    "batch_size = 64\n",
    "model = Sequential()\n",
    "\n",
    "#model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy')\n",
    "model.add(BatchNormalization(input_shape=s.shape[1:]))\n",
    "model.add(ConvLSTM2D(filters=3,kernel_size=(3,3),dropout=0.2,recurrent_dropout=0.1,return_sequences=True))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ConvLSTM2D(filters=3,kernel_size=(3,3),dropout=0.2,recurrent_dropout=0.1,return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13739,
     "status": "ok",
     "timestamp": 1549569485652,
     "user": {
      "displayName": "AMIT TIWARY",
      "photoUrl": "https://lh4.googleusercontent.com/-89DLdjchEVs/AAAAAAAAAAI/AAAAAAAAAAo/jtB5nq61tAg/s64/photo.jpg",
      "userId": "15098214295944816708"
     },
     "user_tz": -330
    },
    "id": "Ac_5PnZrPI2x",
    "outputId": "7e5a0b8a-a1fb-4dd5-c778-cf81dee85ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "229/229 [==============================] - 261s 1s/step - loss: 1.1082 - val_loss: 0.8132\n",
      "Epoch 2/500\n",
      "229/229 [==============================] - 258s 1s/step - loss: 0.9709 - val_loss: 0.7270\n",
      "Epoch 3/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.8406 - val_loss: 0.7145\n",
      "Epoch 4/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.7581 - val_loss: 0.6877\n",
      "Epoch 5/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.7128 - val_loss: 0.6849\n",
      "Epoch 6/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6878 - val_loss: 0.6792\n",
      "Epoch 7/500\n",
      "229/229 [==============================] - 258s 1s/step - loss: 0.6834 - val_loss: 0.6806\n",
      "Epoch 8/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6816 - val_loss: 0.6813\n",
      "Epoch 9/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6795 - val_loss: 0.6799\n",
      "Epoch 10/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.6772 - val_loss: 0.6806\n",
      "\n",
      "Epoch 00010: saving model to ./checkpoint/weights.10-0.68.hdf5\n",
      "Epoch 11/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6784 - val_loss: 0.6779\n",
      "Epoch 12/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6762 - val_loss: 0.6778\n",
      "Epoch 13/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6753 - val_loss: 0.6765\n",
      "Epoch 14/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6752 - val_loss: 0.6736\n",
      "Epoch 15/500\n",
      "229/229 [==============================] - 258s 1s/step - loss: 0.6723 - val_loss: 0.6742\n",
      "Epoch 16/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6714 - val_loss: 0.6731\n",
      "Epoch 17/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6683 - val_loss: 0.6698\n",
      "Epoch 18/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6624 - val_loss: 0.6717\n",
      "Epoch 19/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.6640 - val_loss: 0.6701\n",
      "Epoch 20/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6601 - val_loss: 0.6698\n",
      "\n",
      "Epoch 00020: saving model to ./checkpoint/weights.20-0.67.hdf5\n",
      "Epoch 21/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.6558 - val_loss: 0.6689\n",
      "Epoch 22/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6537 - val_loss: 0.6668\n",
      "Epoch 23/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6479 - val_loss: 0.6617\n",
      "Epoch 24/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.6400 - val_loss: 0.6619\n",
      "Epoch 25/500\n",
      "229/229 [==============================] - 258s 1s/step - loss: 0.6376 - val_loss: 0.6562\n",
      "Epoch 26/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.6343 - val_loss: 0.6569\n",
      "Epoch 27/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.6267 - val_loss: 0.6514\n",
      "Epoch 28/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6299 - val_loss: 0.6492\n",
      "Epoch 29/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6219 - val_loss: 0.6468\n",
      "Epoch 30/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.6159 - val_loss: 0.6437\n",
      "\n",
      "Epoch 00030: saving model to ./checkpoint/weights.30-0.64.hdf5\n",
      "Epoch 31/500\n",
      "229/229 [==============================] - 258s 1s/step - loss: 0.6107 - val_loss: 0.6376\n",
      "Epoch 32/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.6071 - val_loss: 0.6371\n",
      "Epoch 33/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.6079 - val_loss: 0.6376\n",
      "Epoch 34/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.6020 - val_loss: 0.6337\n",
      "Epoch 35/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.6023 - val_loss: 0.6327\n",
      "Epoch 36/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5924 - val_loss: 0.6301\n",
      "Epoch 37/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5880 - val_loss: 0.6245\n",
      "Epoch 38/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5890 - val_loss: 0.6284\n",
      "Epoch 39/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5855 - val_loss: 0.6236\n",
      "Epoch 40/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5804 - val_loss: 0.6270\n",
      "\n",
      "Epoch 00040: saving model to ./checkpoint/weights.40-0.63.hdf5\n",
      "Epoch 41/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5813 - val_loss: 0.6180\n",
      "Epoch 42/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5795 - val_loss: 0.6207\n",
      "Epoch 43/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5748 - val_loss: 0.6134\n",
      "Epoch 44/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5714 - val_loss: 0.6109\n",
      "Epoch 45/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5701 - val_loss: 0.6114\n",
      "Epoch 46/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5661 - val_loss: 0.6104\n",
      "Epoch 47/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5729 - val_loss: 0.6087\n",
      "Epoch 48/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5624 - val_loss: 0.6082\n",
      "Epoch 49/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5635 - val_loss: 0.6118\n",
      "Epoch 50/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5611 - val_loss: 0.6041\n",
      "\n",
      "Epoch 00050: saving model to ./checkpoint/weights.50-0.60.hdf5\n",
      "Epoch 51/500\n",
      "229/229 [==============================] - 261s 1s/step - loss: 0.5613 - val_loss: 0.6033\n",
      "Epoch 52/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5626 - val_loss: 0.6061\n",
      "Epoch 53/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5526 - val_loss: 0.6011\n",
      "Epoch 54/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5516 - val_loss: 0.6075\n",
      "Epoch 55/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5529 - val_loss: 0.5993\n",
      "Epoch 56/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5537 - val_loss: 0.5983\n",
      "Epoch 57/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5512 - val_loss: 0.5972\n",
      "Epoch 58/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5445 - val_loss: 0.5893\n",
      "Epoch 59/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5548 - val_loss: 0.5976\n",
      "Epoch 60/500\n",
      "229/229 [==============================] - 261s 1s/step - loss: 0.5455 - val_loss: 0.5931\n",
      "\n",
      "Epoch 00060: saving model to ./checkpoint/weights.60-0.59.hdf5\n",
      "Epoch 61/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5494 - val_loss: 0.5925\n",
      "Epoch 62/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5446 - val_loss: 0.5916\n",
      "Epoch 63/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5403 - val_loss: 0.5892\n",
      "Epoch 64/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5378 - val_loss: 0.5945\n",
      "Epoch 65/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5367 - val_loss: 0.5881\n",
      "Epoch 66/500\n",
      "229/229 [==============================] - 261s 1s/step - loss: 0.5395 - val_loss: 0.5895\n",
      "Epoch 67/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5383 - val_loss: 0.5870\n",
      "Epoch 68/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5314 - val_loss: 0.5892\n",
      "Epoch 69/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5332 - val_loss: 0.5872\n",
      "Epoch 70/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5419 - val_loss: 0.5865\n",
      "\n",
      "Epoch 00070: saving model to ./checkpoint/weights.70-0.59.hdf5\n",
      "Epoch 71/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5331 - val_loss: 0.5874\n",
      "Epoch 72/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5328 - val_loss: 0.5837\n",
      "Epoch 73/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5272 - val_loss: 0.5836\n",
      "Epoch 74/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5296 - val_loss: 0.5832\n",
      "Epoch 75/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5344 - val_loss: 0.5822\n",
      "Epoch 76/500\n",
      "229/229 [==============================] - 261s 1s/step - loss: 0.5249 - val_loss: 0.5824\n",
      "Epoch 77/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5275 - val_loss: 0.5781\n",
      "Epoch 78/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5284 - val_loss: 0.5802\n",
      "Epoch 79/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5270 - val_loss: 0.5884\n",
      "Epoch 80/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5294 - val_loss: 0.5764\n",
      "\n",
      "Epoch 00080: saving model to ./checkpoint/weights.80-0.58.hdf5\n",
      "Epoch 81/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5211 - val_loss: 0.5777\n",
      "Epoch 82/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5245 - val_loss: 0.5783\n",
      "Epoch 83/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5215 - val_loss: 0.5803\n",
      "Epoch 84/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5225 - val_loss: 0.5729\n",
      "Epoch 85/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5273 - val_loss: 0.5737\n",
      "Epoch 86/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5165 - val_loss: 0.5738\n",
      "Epoch 87/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5164 - val_loss: 0.5745\n",
      "Epoch 88/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5210 - val_loss: 0.5724\n",
      "Epoch 89/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5209 - val_loss: 0.5735\n",
      "Epoch 90/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5225 - val_loss: 0.5752\n",
      "\n",
      "Epoch 00090: saving model to ./checkpoint/weights.90-0.58.hdf5\n",
      "Epoch 91/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5163 - val_loss: 0.5706\n",
      "Epoch 92/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5201 - val_loss: 0.5744\n",
      "Epoch 93/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5222 - val_loss: 0.5719\n",
      "Epoch 94/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5232 - val_loss: 0.5684\n",
      "Epoch 95/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5181 - val_loss: 0.5714\n",
      "Epoch 96/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5202 - val_loss: 0.5665\n",
      "Epoch 97/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5142 - val_loss: 0.5686\n",
      "Epoch 98/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5128 - val_loss: 0.5662\n",
      "Epoch 99/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5175 - val_loss: 0.5669\n",
      "Epoch 100/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5149 - val_loss: 0.5700\n",
      "\n",
      "Epoch 00100: saving model to ./checkpoint/weights.100-0.57.hdf5\n",
      "Epoch 101/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5146 - val_loss: 0.5675\n",
      "Epoch 102/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5146 - val_loss: 0.5690\n",
      "Epoch 103/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5141 - val_loss: 0.5650\n",
      "Epoch 104/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5059 - val_loss: 0.5649\n",
      "Epoch 105/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5153 - val_loss: 0.5688\n",
      "Epoch 106/500\n",
      "229/229 [==============================] - 261s 1s/step - loss: 0.5160 - val_loss: 0.5699\n",
      "Epoch 107/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5131 - val_loss: 0.5705\n",
      "Epoch 108/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5136 - val_loss: 0.5684\n",
      "Epoch 109/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5062 - val_loss: 0.5644\n",
      "Epoch 110/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5077 - val_loss: 0.5682\n",
      "\n",
      "Epoch 00110: saving model to ./checkpoint/weights.110-0.57.hdf5\n",
      "Epoch 111/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5128 - val_loss: 0.5696\n",
      "Epoch 112/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5111 - val_loss: 0.5694\n",
      "Epoch 113/500\n",
      "229/229 [==============================] - 261s 1s/step - loss: 0.5084 - val_loss: 0.5629\n",
      "Epoch 114/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5152 - val_loss: 0.5644\n",
      "Epoch 115/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5090 - val_loss: 0.5621\n",
      "Epoch 116/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5113 - val_loss: 0.5635\n",
      "Epoch 117/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5054 - val_loss: 0.5680\n",
      "Epoch 118/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5026 - val_loss: 0.5627\n",
      "Epoch 119/500\n",
      "229/229 [==============================] - 260s 1s/step - loss: 0.5135 - val_loss: 0.5674\n",
      "Epoch 120/500\n",
      "229/229 [==============================] - 259s 1s/step - loss: 0.5094 - val_loss: 0.5636\n",
      "\n",
      "Epoch 00120: saving model to ./checkpoint/weights.120-0.56.hdf5\n",
      "Epoch 00120: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ca02b2cf8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(X_train, y_train)\n",
    "val_loader = DataLoader(X_val, y_val)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy')\n",
    "model.fit_generator(callbacks=[EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto'), ModelCheckpoint('./checkpoint/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=10)], validation_data=val_loader, generator = train_loader,use_multiprocessing=True,workers=6, verbose=1, shuffle = True, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4590, 160, 10, 11, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = DataLoader(X_test, y_test)\n",
    "#model.predict(test_x, batch_size=64, verbose=1)\n",
    "y = np.zeros((len(X_test),10,11,160))\n",
    "\n",
    "y = test_x.process(y,X_test)\n",
    "y=y.reshape(-1,160,10,11,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4590/4590 [==============================] - 65s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(y, verbose=1)\n",
    "#for i in range(len(y_pred)):\n",
    "#    if y_pred[i]>=0.5:\n",
    "#        y_pred[i]=1\n",
    "#    else:\n",
    "#        y_pred[i]=0\n",
    "y_pred = y_pred.round()\n",
    "y_pred = y_pred.reshape(-1)\n",
    "y_pred = y_pred.astype(int)\n",
    "\n",
    "#binary_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.99      0.71      2537\n",
      "          1       0.52      0.01      0.01      2053\n",
      "\n",
      "avg / total       0.54      0.55      0.40      4590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "6th Feb.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
